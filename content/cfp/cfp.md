---
widget: blank  # See https://wowchemy.com/docs/page-builder/
headless: true  # This file represents a page section.
weight: 10  # Order that this section will appear.

title: Call for Papers

design:
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns: "1"
---

### Important Dates

All deadlines are 11:59PM UTC-12:00 (“anywhere on Earth”).

- **Submission deadline:** <del>10 July 2023</del> <span style="color:red">(Extended) 17 July 2023</span> 
- **Notification of acceptance:** <del>5 August 2023</del> <span style="color:red">(Extended) 11 August 2023</span> 
- **Camera-ready papers due:** 25 August 2023
- **Workshop:** 7 September 2023


Web provides an abundance of knowledge and information that can reach large populations. However, the way in which a text is written (vocabulary, syntax, or text organization/structure), or presented, can make it inaccessible to many people, especially to non-native speakers, people with low literacy, and people with some type of cognitive or linguistic impairments. The results of Adult Literacy Survey (OECD, 2023) indicate that approximately 16.7% of the adult population (averaged over 24 highly-developed countries) requires lexical, 50% syntactic, and 89.4% conceptual simplification of everyday texts (Štajner, 2021).

Research on automatic text simplification (TS), textual accessibility, and readability thus have the potential to improve social inclusion of marginalised populations. These related research areas have increasingly attracted more and more attention in the past ten years, evidenced by the growing number of publications in NLP conferences. While only about 300 articles in Google Scholar mentioned TS in 2010, this number has increased to about 600 in 2015 and is greater than 1000 in 2020 (Štajner, 2021).

Recent research in automatic text simplification has mostly focused on proposing the use of methods derived from the deep learning paradigm (Glavaš and Štajner, 2015; Paetzold and Specia, 2016; Nisioi et al., 2017; Zhang and Lapata, 2017; Martin et al., 2020; Maddela et al., 2021; Sheang and Saggion, 2021). However, there are many important aspects of the automatic text simplification that need the attention of our community: the design of appropriate evaluation metrics, the development of context-aware simplification solutions, the creation of appropriate language resources to support research and evaluation, the deployment of simplification in real environments for real users, the study of discourse factors in text simplification, the identification of factors affecting the readability of a text, etc. To overcome those issues, there is a need for collaboration of CL/NLP researchers, machine learning and deep learning researchers, UI/UX and Accessibility professionals, as well as public organisations representatives (Štajner, 2021).

The proposed TSAR workshop builds upon the recent success of several workshops that covered a subset of our topics of interest, including the SEPLN 2021 Current Trends in Text Simplification (CTTS) and the SimpleText workshop at CLEF 2021, the TSAR-2022 at EMNLP 2022, the recent Special Issue on Text Simplification, Accessibility, and Readability at Frontiers in AI, as well as the birds-of-a-feather event on Text Simplification at NAACL 2021 (over 50 participants).

The TSAR workshop aims to foster collaboration among all parties interested in making information more accessible to all people.  We will discuss recent trends and developments in the area of automatic text simplification, text accessibility, automatic readability assessment, language resources and evaluation for text simplification, etc.

### Topics of Interest

We invite contributions on the following topics (among others):

- Lexical simplification;
- Syntactic simplification;
- Discourse simplification;
- Paragraph simplification;
- Document simplification;
- Modular and end-to-end TS;
- Sequence-to-sequence and zero-shot TS;
- Controllable TS;
- Text complexity assessment;
- Complex word identification and lexical complexity prediction;
- Corpora, lexical resources, and benchmarks for TS;
- Evaluation of TS systems;
- Domain specific TS (e.g. health, legal);
- Other related topics (e.g. empirical and eye-tracking studies);
- Assistive technologies for improving readability and comprehension including those going beyond text.

### Submissions

We welcome three types of papers: long papers, short papers and demos. Submissions should be made to via [START](https://softconf.com/ranlp23/TSAR/)

The papers should present novel research. The review will be double blind and thus all submissions should be anonymized. 

Paper submissions must use the official [RANLP 2023 Templates](http://ranlp.org/ranlp2023/index.php/submissions/), which are available as an [Overleaf](https://www.overleaf.com/latex/templates/instructions-for-ranlp-2023-proceedings/dwjrqsgfrrgm) template and also downloadable directly ([Latex](http://ranlp.org/ranlp2023/Templates/ranlp2023-LaTeX.zip) and [Word](http://ranlp.org/ranlp2023/Templates/ranlp2023-word.docx)). Authors may not modify these style files or use templates designed for other conferences. 
 
Submissions that do not conform to the required styles, including paper size, margin width, and font size restrictions, will be rejected without review.

**Long Papers:**  Long papers must describe substantial, original, completed, and unpublished work. Wherever appropriate, concrete evaluation and analysis should be included.  Long papers may consist of up to eight (8) pages of content, plus unlimited pages of references. Final versions of long papers will be given one additional page of content (up to 9 pages), so that reviewers’ comments can be taken into account. Long papers will be presented orally or as posters as determined by the program committee. The decisions as to which papers will be presented orally and which as poster presentations will be based on the nature rather than the quality of the work. There will be no distinction in the proceedings between long papers presented orally and long papers presented as posters.

**Short Papers:**  Short paper submissions must describe original and unpublished work. Please note that a short paper is not a shortened long paper. Instead, short papers should have a point that can be made in a few pages. Some kinds of short papers include: a small, focused contribution; a negative result; an opinion piece; an interesting application nugget. Short papers may consist of up to four (4) pages of content, plus unlimited pages of references. Final versions of short papers will be given one additional page of content (up to 5 pages), so that reviewers' comments can be taken into account. Short papers will be presented orally or as posters as determined by the program committee. While short papers will be distinguished from long papers in the proceedings, there will be no distinction in the proceedings between short papers presented orally and short papers presented as posters. 

**Demo Papers:**  Demos should be no more than two (2) pages, including references, and should describe implemented systems related to the topics of interest of the workshop. It also should include a link to a short screencast of the working software. In addition, authors of demo papers must be willing to present a demo of their system during TSAR 2023.

### Program Committee

- Bruce W.	Lee	(University of Pennsylvania)
- Christina	Niklaus	(University of St. Gallen)
- Fernando Alva-Manchego (Cardiff University)
- Giulia	Venturi	(Institute of Computational Linguistics "Antonio Zampolli" (ILC-CNR))
- Horacio	Saggion	(Universitat Pompeu Fabra)
- Jaap	Kamps	(University of Amsterdam)
- Jasper	Degraeuwe	(Ghent University)
- Jipeng	Qiang	(Yangzhou University)
- Kim Cheng	Sheang	(Universitat Pompeu Fabra)
- Laura	Vásquez-Rodríguez	(University of Manchester)
- Liana	Ermakova	(HCTI EA-4249, Université de Bretagne Occidentale)
- Maja	Popović	(ADAPT, Dublin City University)
- Matthew	Shardlow (Manchester Metropolitan University)
- Mounica	Maddela	(Georgia Institute of Technology)
- Natalia	Grabar	(CNRS STL UMR8163, Université de Lille)
- Oliver Alonzo (Rochester Institute of Technology)
- Philippe	Laban	(Salesforce Research)
- Piotr	Przybyła	(Universitat Pompeu Fabra)
- Regina	Stodden	(Heinrich Heine University Düsseldorf)
- Rodrigo Alarcon (Universidad Carlos III de Madrid)
- Rémi	Cardon	(CENTAL, ILC, Université Catholique de Louvain)
- Sarah	Ebling	(University of Zurich)
- Susana	Bautista	(Universidad Francisco de Vitoria)
- Sweta	Agrawal (University of Maryland)
- Tadashi	Nomoto	(National Institute of Japanese Literature)
- Tannon	Kew	(University of Zurich)

